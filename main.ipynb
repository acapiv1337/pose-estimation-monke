{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose import PoseEstimator\n",
    "\n",
    "pose = PoseEstimator()\n",
    "\n",
    "# Show image with labeled keypoints\n",
    "# pose.show_image()\n",
    "\n",
    "# # Get keypoints dictionary for ML\n",
    "# keypoints_dicts = pose.keypoints_to_dict()\n",
    "# for i, person in enumerate(keypoints_dicts):\n",
    "#     print(f\"Person {i+1}:\")\n",
    "#     for part, values in person.items():\n",
    "#         print(f\"  {part}: x_norm={values[0]:.2f}, y_norm={values[1]:.2f}, conf={values[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "d164f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "\n",
    "# # --- Configuration ---\n",
    "# video_path = \"train test/WIN_20251020_16_28_55_Pro.mp4\"      # Path to your video\n",
    "# output_dir = \"frames\"               # Folder to save frames\n",
    "# frame_interval = 1                  # Save every frame (1 = every frame, 5 = every 5th frame)\n",
    "\n",
    "# # --- Ensure output directory exists ---\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # --- Open video ---\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "# if not cap.isOpened():\n",
    "#     raise IOError(f\"Cannot open video file: {video_path}\")\n",
    "\n",
    "# frame_count = 0\n",
    "# saved_count = 0\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break  # End of video\n",
    "\n",
    "#     if frame_count % frame_interval == 0:\n",
    "#         # Save frame as image\n",
    "#         filename = os.path.join(output_dir, f\"frame_{saved_count:05d}.jpg\")\n",
    "#         cv2.imwrite(filename, frame)\n",
    "#         saved_count += 1\n",
    "\n",
    "#     frame_count += 1\n",
    "\n",
    "# cap.release()\n",
    "# print(f\"✅ Done! Saved {saved_count} frames to '{output_dir}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
>>>>>>> 26860b3 (feat: experiment on extract point from video then predict)
   "id": "02f352df",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected = ['nose_x', 'nose_y', 'left_eye_x', 'left_eye_y', 'right_eye_x', 'right_eye_y', 'left_ear_x', 'left_ear_y', 'right_ear_x', 'right_ear_y', 'left_shoulder_x', 'left_shoulder_y', 'right_shoulder_x', 'right_shoulder_y', 'left_elbow_x', 'left_elbow_y', 'right_elbow_x', 'right_elbow_y', 'left_wrist_x', 'left_wrist_y', 'right_wrist_x', 'right_wrist_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def flip_and_replace(image_path: str, flip_code: int = 1):\n",
    "    \"\"\"\n",
    "    Flip an image and replace the original file.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        flip_code (int): Flip direction.\n",
    "                         0 = vertical\n",
    "                         1 = horizontal (default)\n",
    "                        -1 = both\n",
    "\n",
    "    Example:\n",
    "        flip_and_replace(\"train test/attack/image.jpg\", 1)\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"❌ Error: Cannot read image '{image_path}'\")\n",
    "        return\n",
    "\n",
    "    # Flip image\n",
    "    flipped = cv2.flip(img, flip_code)\n",
    "\n",
    "    # Overwrite original image\n",
    "    cv2.imwrite(image_path, flipped)\n",
    "    print(f\"✅ Flipped and replaced: {os.path.basename(image_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69828ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = \"train test/sendiri\"\n",
    "data = []\n",
    "\n",
    "# Get all folders (class names)\n",
    "folders = [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]\n",
    "\n",
    "for folder in folders:\n",
    "    class_path = os.path.join(path, folder)\n",
    "    files = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "\n",
    "    print(f\"\\nClass: {folder}\")\n",
    "    for file in files:\n",
    "        image_path = os.path.join(class_path, file)\n",
    "        \n",
    "        # Run pose estimation\n",
    "        pose.predict(image_path)\n",
    "\n",
    "        # Get keypoints as dictionary\n",
    "        keypoints = pose.keypoints_to_dict()\n",
    "        # Add metadata: filename and class label\n",
    "        keypoints[\"class\"] = folder\n",
<<<<<<< HEAD
    "        # pose.show_image()  # optional for visualization\n",
=======
    "        pose.show_image()  # optional for visualization\n",
>>>>>>> 26860b3 (feat: experiment on extract point from video then predict)
    "\n",
    "        # Store into list\n",
    "        data.append(keypoints)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"\\n✅ DataFrame preview:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "aaff7bb9",
=======
   "id": "a15b276f",
>>>>>>> 26860b3 (feat: experiment on extract point from video then predict)
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fecb243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "X = df.drop(columns=['class'], errors='ignore')\n",
    "X = df[feature_selected]\n",
    "y = df['class']\n",
    "\n",
    "# Encode string labels to numeric\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.1,\n",
    "    stratify=y_encoded,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Decode labels back to original strings for readability\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test_decoded, y_pred_decoded))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_decoded, y_pred_decoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test_decoded, y_pred_decoded, labels=label_encoder.classes_)\n",
    "\n",
    "# Create a DataFrame for easier visualization\n",
    "cm_df = pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df)\n",
    "\n",
    "# Optional: visualize using heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix per Class')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model.save_model(\"xgb_model.json\")        # XGBoost native format\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")  # Save label encoder\n",
    "print(\"✅ Model and encoder saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095752a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose.predict(\"predict/ph_007_sandro_005_pw1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bcb623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_frame(frame):\n",
    "    \"\"\"\n",
    "    Replace this with the same preprocessing logic you used during training.\n",
    "    For example: pose keypoints, color histograms, etc.\n",
    "    \"\"\"\n",
    "    # Example placeholder (resize + flatten)\n",
    "    frame_resized = cv2.resize(frame, (64, 64))\n",
    "    return frame_resized.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2fb50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose import PoseEstimator\n",
    "\n",
    "pose = PoseEstimator(\"yolov8s-pose.pt\")\n",
    "df = pose.predict_video(\"predict/WhatsApp Video 2025-10-15 at 15.53.00_3003c314.mp4\", save_path=\"annotated_output.mp4\", display=True)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get all keypoints as dict\n",
    "keypoints_dict = pose.keypoints_to_dict()\n",
    "\n",
    "# Convert to DataFrame for easy column selection\n",
    "x_df = pd.DataFrame([keypoints_dict])  # single row\n",
    "\n",
    "# Keep only selected features\n",
    "x_input = x_df[feature_selected].values  # numpy array ready for model\n",
    "\n",
    "# Make prediction\n",
    "y_pred = model.predict(x_input)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_input)\n",
    "decoded_pred = label_encoder.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c615976",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "feature_importance = pd.Series(importances, index=X_train.columns).sort_values(ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc35feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Encode class as numbers for correlation\n",
    "df_corr = df.copy()\n",
    "df_corr['class_encoded'] = LabelEncoder().fit_transform(df_corr['class'])\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df_corr.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "ICON_DIR = \"image\"  # Folder containing class icons (attack.png, idea.png, stand.png, think.png)\n",
    "\n",
    "def overlay_icon(frame, class_label, icon_size=(150, 150), position=(30, 30)):\n",
    "    \"\"\"\n",
    "    Overlay class icon on video frame.\n",
    "    \"\"\"\n",
    "    icon_path = os.path.join(ICON_DIR, f\"{class_label.lower()}.png\")\n",
    "    \n",
    "    if not os.path.exists(icon_path):\n",
    "        # fallback: text label if image missing\n",
    "        cv2.putText(\n",
    "            frame, f\"{class_label}\",\n",
    "            (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2\n",
    "        )\n",
    "        return frame\n",
    "\n",
    "    icon = cv2.imread(icon_path, cv2.IMREAD_UNCHANGED)\n",
    "    if icon is None:\n",
    "        return frame\n",
    "\n",
    "    icon = cv2.resize(icon, icon_size)\n",
    "\n",
    "    # Ensure it fits in frame\n",
    "    y1, y2 = position[1], position[1] + icon.shape[0]\n",
    "    x1, x2 = position[0], position[0] + icon.shape[1]\n",
    "    if y2 > frame.shape[0] or x2 > frame.shape[1]:\n",
    "        return frame  # Skip if out of bounds\n",
    "\n",
    "    # If icon has alpha channel (transparency)\n",
    "    if icon.shape[2] == 4:\n",
    "        alpha = icon[:, :, 3] / 255.0\n",
    "        for c in range(3):\n",
    "            frame[y1:y2, x1:x2, c] = (\n",
    "                alpha * icon[:, :, c] + (1 - alpha) * frame[y1:y2, x1:x2, c]\n",
    "            )\n",
    "    else:\n",
    "        frame[y1:y2, x1:x2] = icon\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "# Example usage after classification\n",
    "def display_prediction(frame, class_label, classifier_name=\"XGBoost\"):\n",
    "    # Overlay model name\n",
    "    cv2.putText(\n",
    "        frame, f\"Model: {classifier_name}\",\n",
    "        (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2\n",
    "    )\n",
    "\n",
    "    # Overlay class icon or text\n",
    "    frame = overlay_icon(frame, class_label, icon_size=(150, 150), position=(30, 50))\n",
    "\n",
    "    # Also print class label below\n",
    "    cv2.putText(\n",
    "        frame, f\"Class: {class_label}\",\n",
    "        (30, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2\n",
    "    )\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose import PoseEstimator\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# === Load your trained model and label encoder ===\n",
    "model = xgb.XGBClassifier()\n",
    "model.load_model(\"xgb_model.json\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "# === Define the same feature order used during training ===\n",
    "feature_selected = ['nose_x', 'nose_y', 'left_eye_x', 'left_eye_y', 'right_eye_x', 'right_eye_y', 'left_ear_x', 'left_ear_y', 'right_ear_x', 'right_ear_y', 'left_shoulder_x', 'left_shoulder_y', 'right_shoulder_x', 'right_shoulder_y', 'left_elbow_x', 'left_elbow_y', 'right_elbow_x', 'right_elbow_y', 'left_wrist_x', 'left_wrist_y', 'right_wrist_x', 'right_wrist_y']\n",
    "# === Initialize pose estimator ===\n",
    "pose = PoseEstimator(\"yolov8s-pose.pt\")\n",
    "\n",
    "# === Open video ===\n",
    "video_path = \"predict/WhatsApp Video 2025-10-15 at 15.53.00_3003c314.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_idx = 0\n",
    "predictions = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # --- Pose detection ---\n",
    "    results = pose.model.predict(frame, verbose=False)\n",
    "    pose.results = results\n",
    "    kpts_dict = pose.keypoints_to_dict()\n",
    "\n",
    "    if kpts_dict:\n",
    "        df = pd.DataFrame([kpts_dict])\n",
    "\n",
    "        # Select same features as training\n",
    "        X_input = df.reindex(columns=feature_selected, fill_value=0)\n",
    "\n",
    "        # Predict class\n",
    "        y_pred = model.predict(X_input)\n",
    "        class_label = label_encoder.inverse_transform(y_pred)[0]\n",
    "\n",
    "        predictions.append((frame_idx, class_label))\n",
    "\n",
    "        # --- Display on video ---\n",
    "        annotated_frame = results[0].plot()\n",
    "        annotated_frame = overlay_icon(annotated_frame, class_label)\n",
    "        cv2.imshow(\"Pose Classification\", annotated_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "pred_df = pd.DataFrame(predictions, columns=[\"frame\", \"predicted_class\"])\n",
    "print(pred_df.head())\n",
    "\n",
    "# Save results\n",
    "pred_df.to_csv(\"frame_predictions.csv\", index=False)\n",
    "print(\"✅ Saved frame-by-frame predictions to frame_predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
